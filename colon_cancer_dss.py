# -*- coding: utf-8 -*-
"""Colon-cancer-DSS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MbCbrwlBY9XUQLxREJG4hry_rX9IdbjL
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix
import glob
import os

# Import machine learning and deep learning libraries
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# ------------------------------ #
# 1. Load multiple CSV files
# ------------------------------ #

# Define the path to the folder containing your CSV files
folder_path = '/content/drive/MyDrive/wANNOVAR-exome'  # Change this to the path where CSVs are located

# Use glob to get all CSV file paths in the folder
csv_files = glob.glob(os.path.join(folder_path, "*.csv"))

# Create an empty list to store DataFrames
df_list = []

# Loop over CSV file paths and read them into a DataFrame
for file in csv_files:
    df = pd.read_csv(file, low_memory=False)  # Set low_memory=False to avoid DtypeWarning
    df_list.append(df)

# Concatenate all DataFrames into one
df_combined = pd.concat(df_list, ignore_index=True)

# Select relevant columns for analysis
cols_of_interest = [
    'Chr', 'Start', 'End', 'Ref', 'Alt',                    # Variant-Specific Information
    'Func.refGeneWithVer', 'ExonicFunc.refGeneWithVer',     # Functional Annotation
    'Gene.refGeneWithVer', 'GeneDetail.refGeneWithVer', 'AAChange.refGeneWithVer', # Gene Information
    'SIFT_score', 'Polyphen2_HVAR_score', 'CADD_phred',     # Pathogenicity Predictions
    'Otherinfo8', 'Otherinfo9'                              # VCF Quality Metrics
]

df_filtered = df_combined[cols_of_interest].copy()  # Ensure itâ€™s a copy, not a slice

# Handle missing values and categorical encoding

# Encoding categorical columns
label_encoder = LabelEncoder()

df_filtered['Func.refGeneWithVer'] = label_encoder.fit_transform(df_filtered['Func.refGeneWithVer'].astype(str))
df_filtered['ExonicFunc.refGeneWithVer'] = label_encoder.fit_transform(df_filtered['ExonicFunc.refGeneWithVer'].astype(str))
df_filtered['Gene.refGeneWithVer'] = label_encoder.fit_transform(df_filtered['Gene.refGeneWithVer'].astype(str))
df_filtered['GeneDetail.refGeneWithVer'] = label_encoder.fit_transform(df_filtered['GeneDetail.refGeneWithVer'].astype(str))
df_filtered['AAChange.refGeneWithVer'] = label_encoder.fit_transform(df_filtered['AAChange.refGeneWithVer'].astype(str))

# Convert pathogenicity scores to numeric, fill missing values with medians
df_filtered['SIFT_score'] = pd.to_numeric(df_filtered['SIFT_score'], errors='coerce')
df_filtered['Polyphen2_HVAR_score'] = pd.to_numeric(df_filtered['Polyphen2_HVAR_score'], errors='coerce')
df_filtered['CADD_phred'] = pd.to_numeric(df_filtered['CADD_phred'], errors='coerce')

df_filtered['CADD_phred'] = df_filtered['CADD_phred'].fillna(df_filtered['CADD_phred'].median())
df_filtered['Polyphen2_HVAR_score'] = df_filtered['Polyphen2_HVAR_score'].fillna(df_filtered['Polyphen2_HVAR_score'].median())
df_filtered['SIFT_score'] = df_filtered['SIFT_score'].fillna(df_filtered['SIFT_score'].median())

# Convert 'Chr' to one-hot encoding, drop unnecessary columns
df_filtered = pd.get_dummies(df_filtered, columns=['Chr'], drop_first=True)

# Define the feature matrix and the target variable
X = df_filtered.drop(columns=['Gene.refGeneWithVer'])  # Use all columns except the target
y = df_filtered['Gene.refGeneWithVer']  # Target variable (encoded)

# Ensure all features are numerical
X = X.apply(pd.to_numeric, errors='coerce').fillna(0)  # Fill missing values with 0 as a fallback

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ------------------------------ #
# 2. RandomForest Classifier (Machine Learning Model)
# ------------------------------ #
rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)
rf_clf.fit(X_train, y_train)

# RandomForest Predictions
y_pred_rf = rf_clf.predict(X_test)

# RandomForest Evaluation
print("RandomForest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("RandomForest Classification Report:\n", classification_report(y_test, y_pred_rf))

# Feature importance (optional, for RandomForest)
importances = rf_clf.feature_importances_
feature_names = X.columns
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

print(importance_df)

# Confusion matrix for RandomForest
conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
print("Confusion Matrix (RF):\n", conf_matrix_rf)

# ------------------------------ #
# 3. Deep Neural Network (DNN Model using Keras)
# ------------------------------ #
# Build the neural network
model = Sequential()

# Input layer and first hidden layer
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))

# Adding more hidden layers
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))

# Output layer (using softmax for multi-class classification)
model.add(Dense(len(np.unique(y)), activation='softmax'))

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Evaluate the model on the test set
_, accuracy_dnn = model.evaluate(X_test, y_test)
print("DNN Accuracy: %.2f%%" % (accuracy_dnn * 100))

# Predictions for DNN model
y_pred_dnn = np.argmax(model.predict(X_test), axis=-1)

# Classification Report for DNN
print("DNN Classification Report:\n", classification_report(y_test, y_pred_dnn))

# Confusion matrix for DNN
conf_matrix_dnn = confusion_matrix(y_test, y_pred_dnn)
print("Confusion Matrix (DNN):\n", conf_matrix_dnn)

# ------------------------------ #
# 4. Performance Metrics Calculation (Accuracy, Sensitivity, Specificity)
# ------------------------------ #

# Sensitivity (Recall) and Specificity for RandomForest
tn_rf, fp_rf, fn_rf, tp_rf = conf_matrix_rf.ravel()
sensitivity_rf = tp_rf / (tp_rf + fn_rf)
specificity_rf = tn_rf / (tn_rf + fp_rf)

print("RandomForest Sensitivity:", sensitivity_rf)
print("RandomForest Specificity:", specificity_rf)

# Sensitivity (Recall) and Specificity for DNN
tn_dnn, fp_dnn, fn_dnn, tp_dnn = conf_matrix_dnn.ravel()
sensitivity_dnn = tp_dnn / (tp_dnn + fn_dnn)
specificity_dnn = tn_dnn / (tn_dnn + fp_dnn)

print("DNN Sensitivity:", sensitivity_dnn)
print("DNN Specificity:", specificity_dnn)

# ROC-AUC for RandomForest (Optional)
roc_auc_rf = roc_auc_score(y_test, rf_clf.predict_proba(X_test), multi_class='ovr')
print("RandomForest ROC-AUC:", roc_auc_rf)